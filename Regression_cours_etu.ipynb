{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Regression_cours_etu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeoLabUniLaSalle/Python/blob/main/Regression_cours_etu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YmKOTzFjMPW"
      },
      "source": [
        "#La (les) regression(s)\n",
        "\n",
        "Dans ce chapitre, nous allons voir comment utiliser des regressions pour résoudre des problèmes numériques "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEpydqGNjMPY"
      },
      "source": [
        "Commencons par importer les bibliothèques que nous allons utiliser \n",
        "\n",
        "Ici matlplotlib et pylab nous permettent de manipuler les données afin de les mettre sous forme de graphiques\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NhufYwtjMPY",
        "outputId": "6c184f71-18c5-44bb-9bdb-6f428c858ea1"
      },
      "source": [
        "# import classical libraries\n",
        "%matplotlib inline\n",
        "%pylab inline\n",
        "\n",
        "# avoid warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# figure size\n",
        "rcParams['figure.figsize'] = (20, 12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbPKhpA905fy"
      },
      "source": [
        "En cas d'erreur sur ce bloc d'instructions, lancez l'installation du module matplotlib, redémarrez le noyau, puis re-exécutez la dernière cellule de code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g0e-B2p0_ex"
      },
      "source": [
        "import sys  \n",
        "!{sys.executable} -m pip install --user matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHgirqdFjMPZ"
      },
      "source": [
        "### Génération des données \n",
        "\n",
        "Nous allons générer $y$ (notre variable de sortie) and $x$ (notre vairable d'entrée) selon le modèle suivant:\n",
        "$y = \\cos(x) + \\epsilon$, sachant $\\epsilon ~ \\sim \\mathcal{N}\\left(0, (1/4)^2\\right)$.\n",
        "Nous allons le projeter afin de le visualiser l'écart entre notre modèle mathématique et les données réélles "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "065u40eejMPa"
      },
      "source": [
        "# generate x and y\n",
        "random.seed(10) # setting seed for reproducability\n",
        "n = 100 # number of sample\n",
        "x = array([linspace(0, 5, n)]).T\n",
        "y = @ + random.normal(0,0.25,size=shape(x))\n",
        "\n",
        "# plot data\n",
        "plot(x, y, '.')\n",
        "plot(x, cos(x), '-k')\n",
        "ylim([-2, 2])\n",
        "xlabel('x', size=20)\n",
        "ylabel('y', size=20)\n",
        "title('Raw data and true model', size=20)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wkLDPnBjMPa"
      },
      "source": [
        "### Regression linéaire simple\n",
        "\n",
        "Dans un modèle de regression simple nous cherchons a jsuter $y = \\beta_0 + \\beta_1 x$ avec $\\beta_0$ notre odronnées a l'origine $\\beta_1$ notre coefficient directeur. Les fonction génériques de scikit-learn utilisé sont les suivantes :\n",
        "- *LinearRegression()* afin de déclarer notre type de modèle de regression\n",
        "- *fit()* pour ajuster le modèle et ajuster le paramtre $\\beta$ \n",
        "- *predict()* Pour appliquer notre modèle appris a la variable $x$ et avoir les prévision appelées $\\widehat{y}$\n",
        "- *intercept_* et *coef_* permettent d'estimer notre paramettre $\\widehat{\\beta}$\n",
        "\n",
        "Afin de valider notre modèle de regression il est important de savoir interpréter et mesurer les réultats. Une métrique régulièrement utilisée est la Root Mean Squared Error (RMSE) définie par : $\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left(y_i - \\widehat{y}_i \\right)^2}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytt7enH8p_Fz"
      },
      "source": [
        "**A vous de jouer:**\n",
        "- Ajustez la régression linéaire\n",
        "- proposer un graphique du modèle appris\n",
        "- Mesurer la RMSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haX54EOIjMPb"
      },
      "source": [
        "# import functions\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# adjust simple linear regression (slm) between x and y\n",
        "reg_slm = @\n",
        "reg_slm@(x, y)\n",
        "\n",
        "# print beta parameters\n",
        "print('beta_0 = ' + str(reg_slm.intercept_))\n",
        "print('beta_1 = ' + str(reg_slm.coef_))\n",
        "\n",
        "# use the fitted model to get predictions on x\n",
        "y_slm = reg_slm@(x)\n",
        "\n",
        "# plot results\n",
        "plot(x, y, '.')\n",
        "plot(x, @, '-r')\n",
        "ylim([-2, 2])\n",
        "xlabel('x', size=20)\n",
        "ylabel('y', size=20)\n",
        "title('Simple linear regression', size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTUVnR7LjMPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fadbb534-7313-4a6a-8dd3-7e30e2a8e4b7"
      },
      "source": [
        "# compute score\n",
        "RMSE_slm = @\n",
        "print('RMSE(slm) = ' + str(RMSE_slm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE(slm) = 0.49293846130808794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8h712A6qieq"
      },
      "source": [
        "Qu'est ce qu'il est possible de conclure sur ce modèle linéaire ? \n",
        "- Daprès la représentation graphique\n",
        "- D'après les métriques mésurées \n",
        "\n",
        "Que proposez vous comme moyens d'augment la precision du modèle ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLJZZEI1jMPd"
      },
      "source": [
        "### Régression linéaire multiple\n",
        "\n",
        "Comme nous l'avons montré précédemment, si nous utilisons uniquement x et la régression linéaire, nous ne sommes pas en mesure d'ajuster correctement les données. Ainsi, nous proposons de générer de nouveaux prédicteurs en utilisant différentes puissances de $x$ telles que $x^1$, $x^2$, $\\dots$, $x^{15}$. Ils seront stockés dans la matrice $X$. Ensuite, nous allons appliquer la régression linéaire entre $X$ et $y$. C'est ce qu'on appelle la régression linéaire multiple (ici, la régression polynomiale). Le modèle est donné par $y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\dots + \\beta_{15} x^{15}$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDts27sCr_1z"
      },
      "source": [
        "**A vous de jouer:**\n",
        "- Ajustez la régression linéaire multiple et calculez la RMSE\n",
        "- Comparez les résultats à ceux de la régression linéaire simple (selon les présentation de votre choix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyHIEcijjMPd"
      },
      "source": [
        "# generate X matrix\n",
        "X=zeros((n, 15))\n",
        "for i in range(15):\n",
        "    X[:,i] = ravel(x**(i+1))\n",
        "    \n",
        "# adjust multiple linear regression (mlr) between X and y\n",
        "reg_mlr = @\n",
        "reg_mlr@(X, y)\n",
        "y_mlr = reg_mlr@(X)\n",
        "\n",
        "# compute score\n",
        "RMSE_mlr = sqrt(mean((y - y_mlr)**2))\n",
        "print('RMSE(mlr) = ' + str(RMSE_mlr))\n",
        "\n",
        "# plot results\n",
        "plot(x, y, '.')\n",
        "plot(x, y_mlr, '-r')\n",
        "ylim([-2, 2])\n",
        "xlabel('x', size=20)\n",
        "ylabel('y', size=20)\n",
        "title('Multiple linear regression', size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNfg-czDjMPe"
      },
      "source": [
        "### Validation croisée pour choisir le meilleur nombre de paramètres\n",
        "\n",
        "Dans les exemples précédents, nous avons vu que si nous ajoutons des composantes, nous réduisons le score RMSE. Mais, comme nous utilisons les mêmes ensembles de données pour ajuster et tester le modèle, il se peut que nous surajustons les données... Pour tester cela et évaluer le nombre optimal de composnates dans la régression linéaire multiple, nous proposons d'utiliser la procédure de validation croisée suivante :\n",
        "- diviser le jeu de données de façon aléatoire (2/3 pour l'apprentissage et 1/3 pour le test) pour chaque itération\n",
        "- utiliser 1000 itérations\n",
        "- calculer la médiane de la RMSE des 1000 itérations.\n",
        "\n",
        "Cette procédure est facile à mettre en œuvre dans scikit-learn en utilisant *ShuffleSplit()* et *cross_val_score()*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzeuWTJesk6W"
      },
      "source": [
        "**Questions:**\n",
        "- Déclarer la validation croisée\n",
        "- Calculer le RMSE pour chaque degré du polynôme par validation croisée\n",
        "- Appliquer la régression avec le nombre optimal de degrés pour la régression polynomiale\n",
        "- Tracer et comparer cet ajustement au vrai modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVxikZ4CjMPe"
      },
      "source": [
        "# import functions\n",
        "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
        "\n",
        "# declare the cross-validation procedure (cvp)\n",
        "cvp = ShuffleSplit(n_splits=1000, test_size=1/3, train_size=2/3)\n",
        "\n",
        "# example of computed RMSE on 100 cross-validations using multiple linear regression\n",
        "RMSE = sqrt(-cross_val_score(reg_mlr, X, y, scoring='neg_mean_squared_error', cv=cvp))\n",
        "\n",
        "# define the number of degrees between 1 and 15\n",
        "n_degrees = 15\n",
        "degrees = range(1, 16)\n",
        "\n",
        "# loop on number of predictors and compute mean RMSE\n",
        "tab_RMSE_mlr = zeros(n_degrees)\n",
        "for i in range(n_degrees):\n",
        "    tab_RMSE_mlr[i] = mean(sqrt(-cross_val_score(reg_mlr, X@, y, scoring='neg_mean_squared_error', cv=cvp)))\n",
        "\n",
        "# plot results\n",
        "plot(@)\n",
        "xlabel('Degree of the polynomial', size=20)\n",
        "ylabel('RMSE', size=20)\n",
        "title('Cross-validation', size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKZJI6zhjMPe"
      },
      "source": [
        "# apply polynomial regression with 3 degrees\n",
        "@\n",
        "@\n",
        "@\n",
        "\n",
        "# plot results\n",
        "plot(x, y, '.')\n",
        "line1, = plot(x, y_mlr, '-r')\n",
        "line2, = plot(x, cos(x), '-k')\n",
        "ylim([-2, 2])\n",
        "xlabel('x', size=20)\n",
        "ylabel('y', size=20)\n",
        "legend([line1, line2], ['3 degrees polynomial', 'true model'], prop={'size': 20})\n",
        "title('Multiple linear regression', size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "fvlzt0RUjMPf"
      },
      "source": [
        "### Régression Lasso\n",
        "\n",
        "Une autre façon de sélectionner le modèle optimal consiste à utiliser la régression Lasso. Lasso ajoute une contrainte dispersée sur les paramètres de $\\beta$ et essaie de trouver les paramètres de $\\beta$ qui minimisent : $\\sum_{i=1}^n \\left( y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{i,j} \\right)^2 + \\alpha\\sum_{j=1}^p \\left| \\beta_j \\right|$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "356miL1xs7Kr"
      },
      "source": [
        "**A vous de jouer:**\n",
        "- Générer $\\alpha = (10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}, 1)$.\n",
        "- Pour chaque alpha, calculez le RMSE meadien par validation croisée\n",
        "- Pour le meilleur paramètre alpha, examinez les paramètres $\\beta$ estimés\n",
        "- Tracer et comparer cet ajustement au vrai modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xda15VrNjMPf"
      },
      "source": [
        "# import functions\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# define the alphas between 10^(-4) and 1\n",
        "n_alphas = 10\n",
        "alphas = logspace(-4, 0, @)\n",
        "\n",
        "# loop on the alpha parameters and compute mean RMSE\n",
        "tab_RMSE_lasso = zeros(n_alphas)\n",
        "for i in range(n_alphas):\n",
        "    reg_lasso = @(alphas[i])\n",
        "    tab_RMSE_lasso[i] = mean(sqrt(-cross_val_score(reg_lasso, X, y, scoring='neg_mean_squared_error', cv=cvp)))\n",
        "\n",
        "# plot results\n",
        "plot(alphas, tab_RMSE_lasso)\n",
        "xscale('log')\n",
        "xlabel('Alpha coefficients (lasso)', size=20)\n",
        "ylabel('RMSE', size=20)\n",
        "title('Cross-validation', size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWkL_Fi2jMPg"
      },
      "source": [
        "# adjust lasso regression between X and y\n",
        "reg_lasso = @(alpha=@)\n",
        "@\n",
        "@\n",
        "# print beta parameters\n",
        "print('beta: ' + str(reg_lasso.coef_))\n",
        "\n",
        "# plot results\n",
        "plot(x, y, '.')\n",
        "line1, = plot(x, y_lasso, '-r')\n",
        "line2, = plot(x, cos(x), '-k')\n",
        "ylim([-2, 2])\n",
        "xlabel('x', size=20)\n",
        "ylabel('y', size=20)\n",
        "title('Lasso regression', size=20)\n",
        "legend([line1, line2], ['lasso regression', 'true model'], prop={'size': 20})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2la4ZUPujMPg"
      },
      "source": [
        "### Arbre et Regression forest\n",
        "\n",
        "Maintenant, nous proposons d'utiliser des méthodes de régression non linéaire. Dans ce cas, nous **n'utiliserons plus X** (la matrice avec les 15 degrés du polynôme) mais nous **seulement x** (le vecteur d'entrée initial). Nous testons d'abord l'arbre de régression. Un paramètre important dans cette technique est la profondeur de l'arbre : vous optimiserez ce paramètre par validation croisée. Ensuite, nous construirons une regression forest et tracerons les valeurs prédites.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kekwqObtZPN"
      },
      "source": [
        "**A vous de jouer:**\n",
        "- Trouvez la profondeur optimale de l'arbre par validation croisée en utilisant le paramètre *max_depth* de *DecisionTreeRegressor()*.\n",
        "- Dessinez l'arbre de régression correspondant\n",
        "- Construire une forêt de régression avec 1000 arbres en utilisant le paramètre *n_estimators* de *RandomForestRegressor()*.\n",
        "- Tracer et comparer cet ajustement à l'état vrai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sech-scxjMPg"
      },
      "source": [
        "# import functions\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# define the max depths between 1 and 10\n",
        "n_depths = 10\n",
        "depths = linspace(1, 10, n_depths)\n",
        "\n",
        "# loop on the max_depth parameter and compute median RMSE\n",
        "tab_RMSE_tree = zeros(n_depths)\n",
        "for i in range(n_depths):\n",
        "    reg_tree = @(max_depth=@)\n",
        "    tab_RMSE_tree[i] = median(sqrt(-cross_val_score(reg_tree, x, y, scoring='neg_mean_squared_error', cv=cvp)))\n",
        "\n",
        "# plot results\n",
        "plot(depths, tab_RMSE_tree)\n",
        "xlabel('Max depth (tree)', size=20)\n",
        "ylabel('RMSE', size=20)\n",
        "title('Cross-validation', size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKkExvgQjMPh"
      },
      "source": [
        "# if needed, install library using pip\n",
        "#!pip install python-graphviz\n",
        "\n",
        "# import functions\n",
        "from sklearn.tree import export_graphviz\n",
        "from graphviz import Source\n",
        "\n",
        "# adjust regression tree with optimal depth\n",
        "reg_tree = @(max_depth=4)\n",
        "reg_tree.fit(x, y)\n",
        "@\n",
        "\n",
        "# export the tree to \"plot_tree.pdf\"\n",
        "plot_tree = export_graphviz(reg_tree, out_file=None) \n",
        "graph = Source(plot_tree) \n",
        "graph.render(\"plot_tree\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiLEB_6xjMPh"
      },
      "source": [
        "# import functions\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# adjust regression forest between X and y using 1000 trees\n",
        "reg_forest = @(n_estimators=@, max_depth=@)\n",
        "@\n",
        "@\n",
        "\n",
        "# plot results\n",
        "plot(x, y, '.')\n",
        "line1, = plot(x, y_tree, '-r')\n",
        "line2, = plot(x, y_forest, '-g')\n",
        "line3, = plot(x, cos(x), '-k')\n",
        "ylim([-2, 2])\n",
        "xlabel('x', size=20)\n",
        "ylabel('y', size=20)\n",
        "title('Regression forest', size=20)\n",
        "legend([@, @, @], ['1 tree', '1000 trees', 'true model'], prop={'size': 20})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fajwPAptjMPh"
      },
      "source": [
        "### Régression linéaire locale\n",
        "\n",
        "Super, vous êtes maintenant un expert en science des données sur scikit learn ! C'est maintenant à votre tour de coder une méthode. Je vous propose de coder la régression linéaire locale. Malheureusement, cette méthode de régression non linéaire n'est pas fournie par scikit-learn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utmjum2UuqyT"
      },
      "source": [
        "\n",
        "**A vous de jouer :**\n",
        "- Coder la régression linéaire locale\n",
        "- Ajuster la régression linéaire locale avec $\\lambda=0.2$.\n",
        "- Tracer et comparer cet ajustement au vrai modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "JB3a7SRvjMPh"
      },
      "source": [
        "# function to compute weights using a Gaussian kernel\n",
        "def compute_weights(x_star, x, lmbda):\n",
        "    \n",
        "    # apply the Gaussian kernel\n",
        "    w = exp((-(x_star-x)**2)/lmbda)\n",
        "    \n",
        "    # normalize the weights\n",
        "    w = w/sum(w)\n",
        "    \n",
        "    # return the weights\n",
        "    return w\n",
        "\n",
        "# local linear regression function\n",
        "def local_linear_regression(x, y, lmbda):\n",
        "    \n",
        "    # initialization\n",
        "    y_llr = y*NaN\n",
        "    \n",
        "    # loop on samples\n",
        "    for i in range(len(x)):\n",
        "        \n",
        "        # compute the weights\n",
        "        w = compute_weights(x[i], x, lmbda)\n",
        "        \n",
        "        # apply the weighted regression\n",
        "        reg = LinearRegression()\n",
        "        reg.fit(x, y, ravel(w))\n",
        "        y_llr[i] = reg.predict(array([x[i]]))\n",
        "        \n",
        "    # return the estimations\n",
        "    return y_llr  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5UaewKGjMPi"
      },
      "source": [
        "# adjust local linear regression between x and y\n",
        "y_llr = local_linear_regression(x, y, 0.2)\n",
        "\n",
        "# plot results\n",
        "@\n",
        "@\n",
        "@\n",
        "@\n",
        "@\n",
        "@\n",
        "@\n",
        "@"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}