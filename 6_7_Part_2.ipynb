{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "6_7_Part_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeoLabUniLaSalle/Python/blob/main/6_7_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "kaYS7vPrmyOS"
      },
      "source": [
        "# **Data Science**\n",
        "\n",
        "Machine Learning\n",
        "\n",
        "# **Data Preprocessing**\n",
        "Lyes LAKHAL\n",
        "lyes.lakhal@unilasalle.fr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We will briefly walk through steps for preprocessing raw data with `pandas`\n",
        "and converting them into the tensor format.\n",
        "We will cover more data preprocessing techniques in later chapters.\n",
        "\n",
        "# **2.1 Reading the Dataset**\n",
        "\n",
        "As an example, we begin by creating an artificial dataset that is stored in a\n",
        "csv (comma-separated values) file `../data/house_tiny.csv`. Data stored in other\n",
        "formats may be processed in similar ways.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 1,
        "tab": [
          "pytorch"
        ],
        "id": "kneXb4JxmyOW"
      },
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
        "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
        "    f.write('2,NA,106000\\n')\n",
        "    f.write('4,titi,178100\\n')\n",
        "    f.write('NA,lulu,140000\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 2,
        "id": "RGSyiGO0myOX"
      },
      "source": [
        "To load the raw dataset from the created csv file,\n",
        "we import the `pandas` package and invoke the `read_csv` function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "B2w78Xm2myOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f230bb47-ea7b-48da-cf67-5d118b5cf9c6"
      },
      "source": [
        "# If pandas is not installed, just uncomment the following line:\n",
        "# !pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(data_file)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms Alley   Price\n",
            "0       NaN  Pave  127500\n",
            "1       2.0   NaN  106000\n",
            "2       4.0  titi  178100\n",
            "3       NaN  lulu  140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "s4VJFX2KmyOZ"
      },
      "source": [
        "# **2.2. Handling Missing Data**\n",
        "\n",
        "Note that \"NaN\" entries are missing values.\n",
        "To handle missing data, typical methods include *imputation* and *deletion*,\n",
        "where imputation replaces missing values with substituted ones,\n",
        "while deletion ignores missing values. Here we will consider imputation.\n",
        "\n",
        "By integer-location based indexing (`iloc`), we split `data` into `inputs` and `outputs`,\n",
        "where the former takes the first two columns while the latter only keeps the last column.\n",
        "For numerical values in `inputs` that are missing,\n",
        "we replace the \"NaN\" entries with the mean value of the same column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EmrQ1wAs_q8",
        "outputId": "be18612c-a693-47d1-ca25-d1ab069ca3ef"
      },
      "source": [
        "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
        "print(inputs)\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms Alley\n",
            "0       NaN  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0  titi\n",
            "3       NaN  lulu\n",
            "0    127500\n",
            "1    106000\n",
            "2    178100\n",
            "3    140000\n",
            "Name: Price, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "5-kFhLnumyOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a085d030-2dc7-42fe-c5ae-80a65efb35ff"
      },
      "source": [
        "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
        "inputs = inputs.fillna(inputs.mean())\n",
        "print(inputs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms Alley\n",
            "0       3.0  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0  titi\n",
            "3       3.0  lulu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "zpg93AZHmyOa"
      },
      "source": [
        "For categorical or discrete values in `inputs`, we consider \"NaN\" as a category.\n",
        "Since the \"Alley\" column only takes two types of categorical values \"Pave\" and \"NaN\",\n",
        "`pandas` can automatically convert this column to two columns \"Alley_Pave\" and \"Alley_nan\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "5IqdLFcKmyOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8255015e-2479-4a8a-9f8c-046f951cdd59"
      },
      "source": [
        "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
        "print(inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms  Alley_Pave  Alley_lulu  Alley_titi  Alley_nan\n",
            "0       3.0           1           0           0          0\n",
            "1       2.0           0           0           0          1\n",
            "2       4.0           0           0           1          0\n",
            "3       3.0           0           1           0          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "bc2k9JB_myOb"
      },
      "source": [
        "## **2.3. Conversion to the Tensor Format**\n",
        "\n",
        "Now that all the entries in `inputs` and `outputs` are numerical, they can be converted to the tensor format.\n",
        "Once data are in this format, they can be further manipulated with those tensor functionalities that we have previously introduced.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "yIOtIVQUmyOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7473fd8d-944d-48a9-d022-0e13e5891370"
      },
      "source": [
        "import torch\n",
        "\n",
        "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3., 1., 0., 0., 0.],\n",
              "         [2., 0., 0., 0., 1.],\n",
              "         [4., 0., 0., 1., 0.],\n",
              "         [3., 0., 1., 0., 0.]], dtype=torch.float64),\n",
              " tensor([127500, 106000, 178100, 140000]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 12,
        "id": "MutgX1y6myOd"
      },
      "source": [
        "## Summary\n",
        "\n",
        "* Like many other extension packages in the vast ecosystem of Python, `pandas` can work together with tensors.\n",
        "* Imputation and deletion can be used to handle missing data.\n",
        "\n"
      ]
    }
  ]
}